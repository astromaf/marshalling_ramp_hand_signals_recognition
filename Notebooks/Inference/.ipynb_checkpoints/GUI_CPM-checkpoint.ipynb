{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Real-time visual recognition of \"aircraft ramp hand-signals\" applied to UAVs into airport ground operations.***\n",
    "Author: M.Á. de Frutos Carro\n",
    "(MAD, JUN-2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cornerstone of this project, the \"Convolutional Pose Machines\" optimized for use in JetsonNano, builds on the work described in:\n",
    "\n",
    "- **RUN TensorRT_Pose_Estimation:**\n",
    "Real-time pose estimation accelerated with NVIDIA TensorRT\n",
    "    https://github.com/NVIDIA-AI-IOT/trt_pose\n",
    "\n",
    "Before running this Notebook, make sure you have visited, and followed all the instructions described in that repository.\n",
    "\n",
    "A key step, and that you should only execute once, is to download the model (For this projecy we will use: *resnet18_baseline_att_224x224_A*) and its optimization. Follow the instructions described in the repository demo Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import trt_pose.coco\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from torch2trt import TRTModule\n",
    "from trt_pose.draw_objects import DrawObjects\n",
    "from trt_pose.parse_objects import ParseObjects\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "with open('human_pose.json', 'r') as f:\n",
    "    human_pose = json.load(f)\n",
    "\n",
    "topology = trt_pose.coco.coco_category_to_topology(human_pose)\n",
    "\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "data = torch.zeros((1, 3, HEIGHT, WIDTH)).cuda()\n",
    "\n",
    "OPTIMIZED_MODEL = 'resnet18_baseline_att_224x224_A_epoch_249_trt.pth'\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load(OPTIMIZED_MODEL))\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def preprocess(image):\n",
    "    global device\n",
    "    device = torch.device('cuda')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "parse_objects = ParseObjects(topology)\n",
    "draw_objects = DrawObjects(topology)\n",
    "\n",
    "def get_keypoint(humans, hnum, peaks):\n",
    "    #check invalid human index\n",
    "    kpoint = []\n",
    "    human = humans[0][hnum]\n",
    "    C = human.shape[0]\n",
    "    for j in range(C):\n",
    "        k = int(human[j])\n",
    "        if k >= 0:\n",
    "            peak = peaks[0][j][k]   \n",
    "            peak = (float(peak[1]), float(peak[0]))  # x, y\n",
    "            kpoint.append(peak)\n",
    "        else:    \n",
    "            peak = (float(0.0), float(0.0))\n",
    "            kpoint.append(peak)\n",
    "    return kpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAMERA:**\n",
    "\n",
    "Based on JetCAM: an easy to use Python camera interface for NVIDIA Jetson.\n",
    "https://github.com/NVIDIA-AI-IOT/jetcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for dlinano: \n",
      "crw-rw----+ 1 root video 81, 0 Jun 19 10:25 /dev/video0\n"
     ]
    }
   ],
   "source": [
    "#Camera\n",
    "\n",
    "# Full reset of the camera\n",
    "!echo 'dlinano' | sudo -S systemctl restart nvargus-daemon && printf '\\n'\n",
    "# Check device number\n",
    "!ls -ltrh /dev/video*\n",
    "\n",
    "from jetcam.usb_camera import USBCamera\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "camera = USBCamera(width=WIDTH, height=HEIGHT, capture_fps=30)\n",
    "camera.running = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONTROL PANEL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['STOP', 'AHEAD', 'RIGHT', 'LEFT', 'NONE']\n",
    "DATASETS = ['N1', 'N2', 'N3', 'N4']\n",
    "MODELS = ['DNN','Random Forest']\n",
    "\n",
    "#Poses\n",
    "stop = []\n",
    "ahead = []\n",
    "right = []\n",
    "left = []\n",
    "none = []\n",
    "\n",
    "state=0\n",
    "modelo_type=0\n",
    "\n",
    "#Widget\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "out = ipywidgets.Output()\n",
    "\n",
    "###Video\n",
    "image_w = ipywidgets.Image(format='jpeg',width=300, height=300)\n",
    "\n",
    "\n",
    "###Dataset\n",
    "dataset_widget = ipywidgets.Dropdown(options=DATASETS, description='Dataset')\n",
    "category_widget = ipywidgets.Dropdown(options=CATEGORIES, description='Category')\n",
    "count_widget = ipywidgets.IntText(description='Count',disabled=True)\n",
    "\n",
    "def dataset_dropdown_eventhandler(change):\n",
    "    global state\n",
    "    update_count(state)\n",
    "\n",
    "\n",
    "def category_dropdown_eventhandler(change):\n",
    "    global state\n",
    "    if (change.new == 'STOP'):\n",
    "        state=0\n",
    "    elif (change.new == 'AHEAD'):\n",
    "        state=1\n",
    "    elif (change.new == 'RIGHT'):\n",
    "        state=2\n",
    "    elif (change.new == 'LEFT'):\n",
    "        state=3\n",
    "    elif (change.new == 'NONE'):\n",
    "        state=4\n",
    "    update_count(state)\n",
    "    #with out:\n",
    "       # print(state)\n",
    "\n",
    "def update_count(s):\n",
    "    if (s == 0):\n",
    "        count_widget.value = len(stop)\n",
    "    elif (s == 1):\n",
    "        count_widget.value = len(ahead)\n",
    "    elif (s == 2):\n",
    "        count_widget.value = len(right)\n",
    "    elif (s == 3):\n",
    "        count_widget.value = len(left)\n",
    "    elif (s == 4):\n",
    "        count_widget.value = len(none)\n",
    "        \n",
    "dataset_widget.observe(dataset_dropdown_eventhandler, names='value')\n",
    "category_widget.observe(category_dropdown_eventhandler, names='value')\n",
    "dataset_opt=ipywidgets.VBox([dataset_widget, category_widget, count_widget])\n",
    "\n",
    "###Capture/Save\n",
    "capture_button = ipywidgets.Button(description='CAPTURE')\n",
    "save_button = ipywidgets.Button(description='SAVE')\n",
    "\n",
    "def on_capture_button_clicked(_):\n",
    "    global state\n",
    "    if(state==0):\n",
    "        stop.append(key)\n",
    "    if(state==1):\n",
    "        ahead.append(key)\n",
    "    if(state==2):\n",
    "        right.append(key)\n",
    "    if(state==3):\n",
    "        left.append(key)\n",
    "    if(state==4):\n",
    "        none.append(key)\n",
    "    update_count(state)\n",
    "        \n",
    "def on_save_button_clicked(_):\n",
    "    global state\n",
    "    \n",
    "    if not os.path.exists(dataset_widget.value):\n",
    "        os.makedirs(dataset_widget.value)\n",
    "    \n",
    "    if(state==0):\n",
    "        np_stop= np.asarray(stop)\n",
    "        np.save(dataset_widget.value+'/stop_'+dataset_widget.value+'.npy', np_stop)   \n",
    "    if(state==1):\n",
    "        np_ahead= np.asarray(ahead)\n",
    "        np.save(dataset_widget.value+'/ahead_'+dataset_widget.value+'.npy', np_ahead)   \n",
    "    if(state==2):\n",
    "        np_right= np.asarray(right)\n",
    "        np.save(dataset_widget.value+'/right_'+dataset_widget.value+'.npy', np_right)   \n",
    "    if(state==3):\n",
    "        np_left= np.asarray(left)\n",
    "        np.save(dataset_widget.value+'/left_'+dataset_widget.value+'.npy', np_left)\n",
    "    if(state==4):\n",
    "        np_none= np.asarray(none)\n",
    "        np.save(dataset_widget.value+'/none_'+dataset_widget.value+'.npy', np_none) \n",
    "    \n",
    "    #with out:\n",
    "        #print(state)\n",
    "    \n",
    "capture_button.on_click(on_capture_button_clicked)\n",
    "save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "capture_buttons = ipywidgets.HBox([capture_button, save_button])\n",
    "\n",
    "###Live\n",
    "pause_button = ipywidgets.Button(description='PAUSE')\n",
    "live_button = ipywidgets.Button(description='LIVE')\n",
    "fps_widget = ipywidgets.FloatText(description='FPS:', disabled=True)\n",
    "\n",
    "def on_pause_button_clicked(_):\n",
    "    camera.unobserve_all()\n",
    "     \n",
    "def on_live_button_clicked(_):\n",
    "      camera.observe(main, names='value') \n",
    "        \n",
    "pause_button.on_click(on_pause_button_clicked)\n",
    "live_button.on_click(on_live_button_clicked)\n",
    "live_buttons = ipywidgets.VBox([fps_widget, ipywidgets.HBox([pause_button, live_button])])\n",
    "\n",
    "\n",
    "### Score+Predict\n",
    "run_model_button=ipywidgets.ToggleButton(value=False, description='RUN', icon='check')\n",
    "pred_widget = ipywidgets.Text(description='OUT:',value='', disabled=True)\n",
    "model_widget = ipywidgets.Dropdown(options=MODELS, description='Model')\n",
    "\n",
    "score_widgets = []\n",
    "for category in CATEGORIES:\n",
    "    score_widget = ipywidgets.FloatSlider(min=0.0, max=1.0, \n",
    "                                          description=category, orientation='vertical')\n",
    "    score_widgets.append(score_widget)\n",
    "score_widget = ipywidgets.FloatSlider(min=0.0, max=1.0, description='NO HUMAN', orientation='vertical')\n",
    "score_widgets.append(score_widget)\n",
    "\n",
    "def model_dropdown_eventhandler(change):\n",
    "    global modelo_type\n",
    "    if (change.new == 'Random Forest'):\n",
    "        modelo_type=1\n",
    "    elif (change.new == 'DNN'):\n",
    "        modelo_type=0\n",
    "\n",
    "model_widget.observe(model_dropdown_eventhandler, names='value')\n",
    "\n",
    "def update_modelo(clase, output):\n",
    "    if(run_model_button.value == False):\n",
    "        pred_widget.value= \"NO PREDICTION\"\n",
    "        for i in range(6):\n",
    "            score_widgets[i].value = 0.0\n",
    "    elif(clase==5):\n",
    "        pred_widget.value= \"NO HUMAN\"\n",
    "        for i in range(5):\n",
    "            score_widgets[i].value = 0.0\n",
    "        score_widgets[5].value = 1.0\n",
    "    elif (clase==0):\n",
    "        pred_widget.value= \"STOP\"\n",
    "        score_widgets[0].value = output[0][0]\n",
    "        score_widgets[1].value = output[0][1]\n",
    "        score_widgets[2].value = output[0][2]\n",
    "        score_widgets[3].value = output[0][3]\n",
    "        score_widgets[4].value = output[0][4]\n",
    "        score_widgets[5].value = 0.0\n",
    "    elif (clase==1):\n",
    "        pred_widget.value= \"AHEAD\"\n",
    "        score_widgets[0].value = output[0][0]\n",
    "        score_widgets[1].value = output[0][1]\n",
    "        score_widgets[2].value = output[0][2]\n",
    "        score_widgets[3].value = output[0][3]\n",
    "        score_widgets[4].value = output[0][4]\n",
    "        score_widgets[5].value = 0.0\n",
    "    elif (clase==2):\n",
    "        pred_widget.value= \"RIGHT\"\n",
    "        score_widgets[0].value = output[0][0]\n",
    "        score_widgets[1].value = output[0][1]\n",
    "        score_widgets[2].value = output[0][2]\n",
    "        score_widgets[3].value = output[0][3]\n",
    "        score_widgets[4].value = output[0][4]\n",
    "        score_widgets[5].value = 0.0\n",
    "    elif (clase==3):\n",
    "        pred_widget.value= \"LEFT\"\n",
    "        score_widgets[0].value = output[0][0]\n",
    "        score_widgets[1].value = output[0][1]\n",
    "        score_widgets[2].value = output[0][2]\n",
    "        score_widgets[3].value = output[0][3]\n",
    "        score_widgets[4].value = output[0][4]\n",
    "        score_widgets[5].value = 0.0\n",
    "    elif (clase==4):\n",
    "        pred_widget.value= \"NONE\"\n",
    "        score_widgets[0].value = output[0][0]\n",
    "        score_widgets[1].value = output[0][1]\n",
    "        score_widgets[2].value = output[0][2]\n",
    "        score_widgets[3].value = output[0][3]\n",
    "        score_widgets[4].value = output[0][4]\n",
    "        score_widgets[5].value = 0.0\n",
    "        \n",
    "score=ipywidgets.VBox([ipywidgets.HBox(score_widgets),pred_widget,ipywidgets.HBox([model_widget,run_model_button])])        \n",
    "\n",
    "###ALL\n",
    "all_widget = ipywidgets.HBox([ipywidgets.VBox([ipywidgets.HBox([image_w]),live_buttons,\n",
    "                              dataset_opt,capture_buttons]), ipywidgets.VBox([score])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDICTION MODEL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload Optimized Tensor RT Model\n",
    "loaded = tf.saved_model.load('models/model_n1n2n3_v10')  # loading the converted model\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "\n",
    "# In case KERAS Model (Too Low)\n",
    "#model = tf.keras.models.load_model('models/MAF_ariba_abajo.h5')\n",
    "\n",
    "#Upload Random Forest Model\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "model_rf = pickle.load(open('models/rand_forest_v2.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIVE EXECUTION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(change):\n",
    "    t=time.time()\n",
    "    image = change['new']\n",
    "    data = preprocess(image)\n",
    "    cmap, paf = model_trt(data)\n",
    "    cmap, paf = cmap.detach().cpu(), paf.detach().cpu()\n",
    "    counts, objects, peaks = parse_objects(cmap, paf)#, cmap_threshold=0.15, link_threshold=0.15)\n",
    "    draw_objects(image, counts, objects, peaks)\n",
    "    image_w.value = bgr8_to_jpeg(image[:, ::-1, :])\n",
    "    global model_out\n",
    "    global output\n",
    "    global o_clase\n",
    "    global ellapsed\n",
    "    global modelo_type\n",
    "    \n",
    "    if len(range(counts[0]))>0:    #Check if person detected\n",
    "        #for i in range(counts[0]): #Get Keypoints\n",
    "        global key\n",
    "        key = get_keypoint(objects, 0, peaks)\n",
    "        \n",
    "        if (run_model_button.value) and (time.time()- ellapsed>0.25):\n",
    "            inkey=np.array(key,dtype=np.float32)\n",
    "            inkey=inkey.reshape(1,36)\n",
    "            if(modelo_type == 1):\n",
    "                output=model_rf.predict(inkey) #For RF Model\n",
    "            else:\n",
    "                output= infer(tf.constant(inkey,dtype=float))['LastLayer'] #TRT Model\n",
    "                \n",
    "            clase=np.argmax(output)\n",
    "            ellapsed=time.time()\n",
    "            o_clase=clase\n",
    "        else:\n",
    "            clase=o_clase\n",
    "    else:\n",
    "        clase=5 #No-Human\n",
    "        \n",
    "    fps=(1.0)/(time.time()-t)\n",
    "    fps_widget.value = round(fps,2)\n",
    "    update_modelo(clase,output)\n",
    "    \n",
    "#main({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007c3972578f47d39f746e4a9363f587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(Image(value=b'', format='jpeg', height='300', width='300'),)), VB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Init\n",
    "ellapsed=time.time()\n",
    "output=np.array([0,0,0,0,0], ndmin=2)\n",
    "o_clase=5\n",
    "update_count(0)\n",
    "\n",
    "# Execute\n",
    "camera.observe(main, names='value')\n",
    "display(all_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
