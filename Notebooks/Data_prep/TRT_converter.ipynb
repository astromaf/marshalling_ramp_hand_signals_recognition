{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT Model Optimized\n",
    "TensorRT-based applications perform up to 40x faster than CPU-only platforms during inference. With TensorRT, you can optimize neural network models trained in all major frameworks, calibrate for lower precision with high accuracy\n",
    "See https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENCIÓN:** Última capa del modelo debe estar con name=\"LastLayer\".\n",
    "\n",
    "e.g.:  *keras.layers.Dense(y.shape[1], activation='softmax', **name =\"LastLayer\"**)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/Final/'\n",
    "modelo='model_n1n2n3_v10.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Abrimos el modelo KERAS \".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_X = tf.keras.models.load_model(PATH+modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos un dataset de ejemplo\n",
    "noneDataset=np.load(PATH+'none.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8608925e-17 2.4994437e-05 1.4050877e-25 4.5188310e-14 9.9997497e-01]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Probamos modelo\n",
    "x1=noneDataset[3]\n",
    "x1=x1.reshape(1,36)\n",
    "\n",
    "output=model_X.predict(x1)\n",
    "clase=np.argmax(output)\n",
    "\n",
    "print(output)\n",
    "print(clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Lo guardo en formato TF \".pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/MAF/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: data/Final//model_pb/assets\n",
      "model saved under:  data/Final//model_pb\n"
     ]
    }
   ],
   "source": [
    "#SAVE THE MODEL model_name = \"Model_trt\"\n",
    "model_path_pb = PATH+'/model_pb' # define path to save model in saved model format\n",
    "\n",
    "os.makedirs(model_path_pb, exist_ok=True)\n",
    "\n",
    "tf.saved_model.save(model_X, model_path_pb) \n",
    "print(\"model saved under: \",model_path_pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Optimizamos el modelo con TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "converting to trt-model\n",
      "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
      "\n",
      "converter.convert\n",
      "\n",
      "converter.save\n",
      "INFO:tensorflow:Assets written to: data/Final//model_trt/assets\n",
      "trt-model saved under:  data/Final//model_trt\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TO TENSOR RT\n",
    "\n",
    "model_path_trt = PATH+'/model_trt' # define path to save model in saved model format\n",
    "os.makedirs(model_path_trt, exist_ok=True)\n",
    "\n",
    "print(\"\\nconverting to trt-model\")\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=model_path_pb) \n",
    "# we feed the saved model into this converter function\n",
    "\n",
    "print(\"\\nconverter.convert\")\n",
    "converter.convert()\n",
    "\n",
    "print(\"\\nconverter.save\")\n",
    "converter.save(model_path_trt) # we save the converted model\n",
    "\n",
    "print(\"trt-model saved under: \",model_path_trt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Cargamos modelo optimizado (trt) y probamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD NEW MODEL\n",
    "loaded = tf.saved_model.load(PATH+'/model_trt')  # loading the converted model\n",
    "infer = loaded.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=noneDataset[3]\n",
    "x1=x1.reshape(1,36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.8608925e-17 2.4994437e-05 1.4050877e-25 4.5188310e-14 9.9997497e-01]], shape=(1, 5), dtype=float32)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#PREDICTION\n",
    "output = infer(tf.constant(x1,dtype=float))['LastLayer']   \n",
    "\n",
    "clase=np.argmax(output)\n",
    "print(output)\n",
    "print(clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
