{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET PRE-PROCESSING\n",
    "M.Á. de Frutos (MAD-2020)\n",
    "\n",
    "Analizamos el dataset y genramos CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos capturados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/Final/'\n",
    "PATH_N1='data/Final/N1_MAF/'\n",
    "PATH_N2='data/Final/N2_ERB/'\n",
    "PATH_N3='data/Final/N3_DAD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP\n",
    "stopDataset_N1=np.load(PATH_N1+'stop.npy')\n",
    "stopDataset_N2=np.load(PATH_N2+'stop.npy')\n",
    "stopDataset_N3=np.load(PATH_N3+'stop.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AHEAD\n",
    "aheadDataset_N1=np.load(PATH_N1+'ahead.npy')\n",
    "aheadDataset_N2=np.load(PATH_N2+'ahead.npy')\n",
    "aheadDataset_N3=np.load(PATH_N3+'ahead.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIGHT\n",
    "rightDataset_N1=np.load(PATH_N1+'right.npy')\n",
    "rightDataset_N2=np.load(PATH_N2+'right.npy')\n",
    "rightDataset_N3=np.load(PATH_N3+'right.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEFT\n",
    "leftDataset_N1=np.load(PATH_N1+'left.npy')\n",
    "leftDataset_N2=np.load(PATH_N2+'left.npy')\n",
    "leftDataset_N3=np.load(PATH_N3+'left.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NONE\n",
    "noneDataset_N1=np.load(PATH_N1+'none.npy')\n",
    "noneDataset_N2=np.load(PATH_N2+'none.npy')\n",
    "noneDataset_N3=np.load(PATH_N3+'none.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusionamos en un único Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n"
     ]
    }
   ],
   "source": [
    "#STOP\n",
    "stopDataset= np.append(stopDataset_N1, stopDataset_N2, axis=0)\n",
    "stopDataset= np.append(stopDataset, stopDataset_N3, axis=0)\n",
    "print(len(stopDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n"
     ]
    }
   ],
   "source": [
    "#AHEAD\n",
    "aheadDataset= np.append(aheadDataset_N1, aheadDataset_N2, axis=0)\n",
    "aheadDataset= np.append(aheadDataset, aheadDataset_N3, axis=0)\n",
    "print(len(aheadDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n"
     ]
    }
   ],
   "source": [
    "#RIGHT\n",
    "rightDataset= np.append(rightDataset_N1, rightDataset_N2, axis=0)\n",
    "rightDataset= np.append(rightDataset, rightDataset_N3, axis=0)\n",
    "print(len(rightDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n"
     ]
    }
   ],
   "source": [
    "#LEFT\n",
    "leftDataset= np.append(leftDataset_N1, leftDataset_N2, axis=0)\n",
    "leftDataset= np.append(leftDataset, leftDataset_N3, axis=0)\n",
    "print(len(leftDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n"
     ]
    }
   ],
   "source": [
    "#NONE\n",
    "noneDataset= np.append(noneDataset_N1, noneDataset_N2, axis=0)\n",
    "noneDataset= np.append(noneDataset, noneDataset_N3, axis=0)\n",
    "print(len(noneDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizamos características principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP:  shape\t (18, 2) \tLong: 971 \tNº NaN: 0\n",
      "AHEAD: shape\t (18, 2) \tLong: 973 \tNº NaN: 0\n",
      "RIGHT: shape\t (18, 2) \tLong: 973 \tNº NaN: 0\n",
      "LEFT:  shape\t (18, 2) \tLong: 970 \tNº NaN: 0\n",
      "NONE:  shape\t (18, 2) \tLong: 970 \tNº NaN: 0\n"
     ]
    }
   ],
   "source": [
    "#Analizamos sus caracteríscticas:\n",
    "print('STOP:  shape\\t', stopDataset[0].shape, '\\tLong:',len(stopDataset), '\\tNº NaN:', np.isnan(stopDataset).sum())\n",
    "print('AHEAD: shape\\t', aheadDataset[0].shape, '\\tLong:',len(aheadDataset),'\\tNº NaN:', np.isnan(aheadDataset).sum())\n",
    "print('RIGHT: shape\\t', rightDataset[0].shape, '\\tLong:',len(rightDataset),'\\tNº NaN:', np.isnan(rightDataset).sum())\n",
    "print('LEFT:  shape\\t', leftDataset[0].shape, '\\tLong:',len(leftDataset), '\\tNº NaN:', np.isnan(leftDataset).sum())\n",
    "print('NONE:  shape\\t', noneDataset[0].shape, '\\tLong:',len(noneDataset), '\\tNº NaN:', np.isnan(noneDataset).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud: 18\n",
      "Sample:\n",
      " [[0.47519749 0.27839831]\n",
      " [0.49778932 0.25115982]\n",
      " [0.45600948 0.25830549]\n",
      " [0.5321008  0.27554995]\n",
      " [0.43454909 0.28871176]\n",
      " [0.57479811 0.40900895]\n",
      " [0.402803   0.41639048]\n",
      " [0.6976065  0.31388822]\n",
      " [0.28192973 0.32799914]\n",
      " [0.61405438 0.16229226]\n",
      " [0.38951302 0.14774534]\n",
      " [0.55479592 0.8695296 ]\n",
      " [0.40808836 0.88541853]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.48751718 0.4090299 ]]\n"
     ]
    }
   ],
   "source": [
    "#Mostramosuno de los datos\n",
    "print(\"Longitud:\",len(stopDataset[0]))\n",
    "print(\"Sample:\\n\",stopDataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47519749, 0.27839831],\n",
       "       [0.49778932, 0.25115982],\n",
       "       [0.45600948, 0.25830549],\n",
       "       [0.5321008 , 0.27554995],\n",
       "       [0.43454909, 0.28871176],\n",
       "       [0.57479811, 0.40900895],\n",
       "       [0.402803  , 0.41639048],\n",
       "       [0.6976065 , 0.31388822],\n",
       "       [0.28192973, 0.32799914],\n",
       "       [0.61405438, 0.16229226],\n",
       "       [0.38951302, 0.14774534],\n",
       "       [0.55479592, 0.8695296 ],\n",
       "       [0.40808836, 0.88541853],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.48751718, 0.4090299 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopDataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos DATASET único:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos como nuevo dataset\n",
    "np.save(PATH+'stop.npy', stopDataset) \n",
    "np.save(PATH+'ahead.npy', aheadDataset) \n",
    "np.save(PATH+'right.npy', rightDataset) \n",
    "np.save(PATH+'left.npy', leftDataset)\n",
    "np.save(PATH+'none.npy', noneDataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Añadimos cabeceras.\n",
    "\n",
    "Añadimos las cabeceras según están descritas en \"human_pose.json\" en \"trt_pose/tasks/human_pose\".https://github.com/NVIDIA-AI-IOT/trt_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "        \"nose\",\n",
    "        \"left_eye\",\n",
    "        \"right_eye\",\n",
    "        \"left_ear\",\n",
    "        \"right_ear\",\n",
    "        \"left_shoulder\",\n",
    "        \"right_shoulder\",\n",
    "        \"left_elbow\",\n",
    "        \"right_elbow\",\n",
    "        \"left_wrist\",\n",
    "        \"right_wrist\",\n",
    "        \"left_hip\",\n",
    "        \"right_hip\",\n",
    "        \"left_knee\",\n",
    "        \"right_knee\",\n",
    "        \"left_ankle\",\n",
    "        \"right_ankle\",\n",
    "        \"neck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos sufijo `X`, `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_wristY\n",
      "right_wristX\n",
      "left_wristX\n",
      "neckX\n",
      "left_elbowY\n"
     ]
    }
   ],
   "source": [
    "properLabels = []\n",
    "for label in labels:\n",
    "    properLabels.append(label + 'X')\n",
    "    properLabels.append(label + 'Y')\n",
    "    \n",
    "print (properLabels[19])\n",
    "print (properLabels[20])\n",
    "print (properLabels[18])\n",
    "print (properLabels[34])\n",
    "print (properLabels[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(PATH+'stop.csv', 'w+') as stopcsv:\n",
    "    stopwriter = csv.writer(stopcsv, delimiter=',')\n",
    "    stopwriter.writerow(properLabels)\n",
    "    for cell in stopDataset:\n",
    "        stopwriter.writerow(cell.flatten())\n",
    "        \n",
    "with open(PATH+'ahead.csv', 'w+') as aheadcsv:\n",
    "    aheadwriter = csv.writer(aheadcsv, delimiter=',')\n",
    "    aheadwriter.writerow(properLabels)\n",
    "    for cell in aheadDataset:\n",
    "        aheadwriter.writerow(cell.flatten())\n",
    "\n",
    "with open(PATH+'right.csv', 'w+') as rightcsv:\n",
    "    rightwriter = csv.writer(rightcsv, delimiter=',')\n",
    "    rightwriter.writerow(properLabels)\n",
    "    for cell in rightDataset:\n",
    "        rightwriter.writerow(cell.flatten())\n",
    "        \n",
    "with open(PATH+'left.csv', 'w+') as leftcsv:\n",
    "    leftwriter = csv.writer(leftcsv, delimiter=',')\n",
    "    leftwriter.writerow(properLabels)\n",
    "    for cell in leftDataset:\n",
    "        leftwriter.writerow(cell.flatten())\n",
    "        \n",
    "with open(PATH+'none.csv', 'w+') as nonecsv:\n",
    "    nonewriter = csv.writer(nonecsv, delimiter=',')\n",
    "    nonewriter.writerow(properLabels)\n",
    "    for cell in noneDataset:\n",
    "        nonewriter.writerow(cell.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENCIÓN:** Renombrar CSV generados para no perder datos por sobrescritura accidental ahora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
